{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29debbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0587cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader, model, criterion, optimizer, device, mb):\n",
    "\n",
    "    # Put the model into training mode\n",
    "    model.train()\n",
    "\n",
    "    # Loop over the data using the progress_bar utility\n",
    "    for _, (X, Y) in progress_bar(DataLoaderProgress(dataloader), parent=mb):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        # Compute model output and then loss\n",
    "        output = model(X)\n",
    "        loss = criterion(output, Y)\n",
    "\n",
    "        # - zero-out gradients\n",
    "        optimizer.zero_grad()\n",
    "        # - compute new gradients\n",
    "        loss.backward()\n",
    "        # - update paramters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "59925061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader, model, criterion, device, epoch, num_epochs, mb):\n",
    "\n",
    "    # Put the model into validation/evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    N = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    loss, num_correct = 0, 0\n",
    "\n",
    "    # Tell pytorch to stop updating gradients when executing the following\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for X, Y in dataloader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "            # Compute the model output\n",
    "            output = model(X)\n",
    "            \n",
    "            print(X)\n",
    "            print(Y)\n",
    "            print(output)\n",
    "\n",
    "            # - compute loss\n",
    "            loss += criterion(torch.flatten(output), Y).item()\n",
    "            # - compute the number of correctly classified examples\n",
    "            num_correct += (output.argmax(1) == Y).type(torch.float).sum().item()\n",
    "\n",
    "        loss /= num_batches\n",
    "        accuracy = num_correct / N\n",
    "\n",
    "    message = \"Initial\" if epoch == 0 else f\"Epoch {epoch:>2}/{num_epochs}:\"\n",
    "    message += f\" accuracy={100*accuracy:5.2f}%\"\n",
    "    message += f\" and loss={loss:.3f}\"\n",
    "    mb.write(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6765cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, valid_loader, device, num_epochs):\n",
    "    mb = master_bar(range(num_epochs))\n",
    "\n",
    "    validate(valid_loader, model, criterion, device, 0, num_epochs, mb)\n",
    "\n",
    "    for epoch in mb:\n",
    "        train_one_epoch(train_loader, model, criterion, optimizer, device, mb)\n",
    "        validate(valid_loader, model, criterion, device, epoch + 1, num_epochs, mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f26c1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a model for each team file in the 'teams_five_season_data' folder\n",
    "def load_data_into_models(path): \n",
    "    team_models = []\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        model = Team(path+\"/\"+file)\n",
    "        team_models.append(model)\n",
    "    \n",
    "    return team_models\n",
    "\n",
    "# creates dataloaders from each team model\n",
    "def load_team_models_into_dls(team_models):\n",
    "    team_dataloaders = []\n",
    "    for team in team_models:\n",
    "        dl = torch.utils.data.DataLoader(team, batch_size = 10)\n",
    "        team_dataloaders.append(dl)\n",
    "        \n",
    "    return team_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "442a9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts team names into readable integer encodings\n",
    "# might be simpler just to assign each team an integer\n",
    "def encode_string_as_int(string):\n",
    "    ret = \"\"\n",
    "    for c in string:\n",
    "        ret += str(ord(c))\n",
    "    return int(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5f22c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to create individual model objects for each team\n",
    "class Team ():\n",
    "    def __init__(self, file_path):\n",
    "        file_out = pd.read_csv(file_path)\n",
    "        # x_axis_labels = file_out.iloc[0, 1:8].values\n",
    "        \n",
    "        data = file_out.iloc[1:191, 1:8].values\n",
    "        x = []\n",
    "        y = []\n",
    "        \n",
    "        for match in data:\n",
    "            # convert team names to int encoding\n",
    "            match[0] = encode_string_as_int(match[0])\n",
    "            match[1] = encode_string_as_int(match[1])\n",
    "            \n",
    "            # create lists for input and target data\n",
    "            x.append(np.delete(match, 4).tolist())\n",
    "            y.append(match[4])\n",
    "            \n",
    "        # cast all string input data to ints\n",
    "        for match in x:\n",
    "            for attr in range(0,6):\n",
    "                match[attr] = int(match[attr])\n",
    "                \n",
    "        # cast all string target data to ints \n",
    "        for match_result in range(len(y)):\n",
    "            y[match_result] = int(y[match_result])\n",
    "    \n",
    "        \n",
    "        # print(\"training data:\")\n",
    "        # print(x)\n",
    "        # print()\n",
    "        \n",
    "        # print(\"match results (aka targets):\")\n",
    "        # print(y)\n",
    "        \n",
    "        # final data to train on\n",
    "        self.X_train = torch.tensor(x, dtype = torch.float).float()\n",
    "        # targets (i.e. match scorelines)\n",
    "        self.Y_train = torch.tensor(y, dtype= torch.long)\n",
    "        \n",
    "        # print (self.X_train)\n",
    "        # print (self.Y_train)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.Y_train)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_train[idx], self.Y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "36192046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    aparser = ArgumentParser(\"FIFAI--Train a neural network to predict EPL scorelines.\")\n",
    "    aparser.add_argument(\"epl_data\", type=str, help=\"Path to store/find the EPL games dataset\")\n",
    "    aparser.add_argument(\"--num_epochs\", type=int, default=10)\n",
    "    aparser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    aparser.add_argument(\"--learning_rate\", type=float, default=0.01)\n",
    "    aparser.add_argument(\"--gpu\", action=\"store_true\")\n",
    "\n",
    "    args = aparser.parse_args()\n",
    "\n",
    "    # Use GPU if requested and available\n",
    "    device = \"cuda\" if args.gpu and torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Get models\n",
    "    team_models = load_data_into_models(args.epl_data)\n",
    "\n",
    "    # Get dataloaders\n",
    "    dls = load_team_models_into_dls(team_models)\n",
    "    \n",
    "    # Using the Arsenal model, for example\n",
    "    train_loader = dls[0]\n",
    "    valid_loader = dls[0]\n",
    "    \n",
    "    model = torch.nn.Sequential(nn.Flatten(), torch.nn.Linear(in_features=6, out_features=1))\n",
    "    \n",
    "    # - specifies CrossEntropyLoss as loss criterion\n",
    "    # - specifies Adam as our optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "    train(model, criterion, optimizer, train_loader, valid_loader, device, args.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a09a0bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–ˆ\r",
      "tensor([[6.9118e+19, 8.4111e+24, 1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\r\n",
      "        [8.7101e+23, 6.9118e+19, 1.0000e+00, 2.0000e+00, 1.0000e+00, 0.0000e+00],\r\n",
      "        [6.9118e+19, 8.3116e+13, 1.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00],\r\n",
      "        [8.3117e+27, 6.9118e+19, 0.0000e+00, 3.0000e+00, 3.0000e+00, 1.0000e+00],\r\n",
      "        [6.9118e+19, 7.7105e+36, 3.0000e+00, 1.0000e+00, 4.0000e+00, 1.0000e+00],\r\n",
      "        [6.6111e+31, 6.9118e+19, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\r\n",
      "        [6.9118e+19, 6.7114e+34, 1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\r\n",
      "        [7.7971e+19, 6.9118e+19, 1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\r\n",
      "        [6.6117e+19, 6.9118e+19, 2.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\r\n",
      "        [6.9118e+19, 8.7101e+19, 2.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00]])\r\n",
      "tensor([ 0,  1,  1,  3,  2, -1,  0,  0, -1,  2])\r\n",
      "tensor([[ 3.4086e+24],\r\n",
      "        [-2.7449e+23],\r\n",
      "        [-2.1784e+19],\r\n",
      "        [-2.6196e+27],\r\n",
      "        [ 3.1247e+36],\r\n",
      "        [-2.0836e+31],\r\n",
      "        [ 2.7198e+34],\r\n",
      "        [ 3.4357e+18],\r\n",
      "        [ 7.1718e+18],\r\n",
      "        [ 1.3514e+19]])\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"FIFAI-model.py\", line 253, in <module>\r\n",
      "    main()\r\n",
      "  File \"FIFAI-model.py\", line 211, in main\r\n",
      "    train(model, criterion, optimizer, train_loader, valid_loader, device, args.num_epochs)\r\n",
      "  File \"FIFAI-model.py\", line 91, in train\r\n",
      "    validate(valid_loader, model, criterion, device, 0, num_epochs, mb)\r\n",
      "  File \"FIFAI-model.py\", line 75, in validate\r\n",
      "    loss += criterion(torch.flatten(output), Y).item()\r\n",
      "  File \"/opt/mambaforge/envs/cs152/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\r\n",
      "    return forward_call(*input, **kwargs)\r\n",
      "  File \"/opt/mambaforge/envs/cs152/lib/python3.8/site-packages/torch/nn/modules/loss.py\", line 612, in forward\r\n",
      "    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\r\n",
      "  File \"/opt/mambaforge/envs/cs152/lib/python3.8/site-packages/torch/nn/functional.py\", line 2893, in binary_cross_entropy\r\n",
      "    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)\r\n",
      "RuntimeError: Found dtype Long but expected Float\r\n"
     ]
    }
   ],
   "source": [
    "!python FIFAI-model.py \"../teams_five_season_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66b3379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RNN_Model(nn.Module):\n",
    "#     def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "#         super(Model, self).__init__()\n",
    "\n",
    "#         # Defining some parameters\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.n_layers = n_layers\n",
    "\n",
    "#         # RNN layer\n",
    "#         self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "#         # Linear layer\n",
    "#         self.linear = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         batch_size = x.size(0)\n",
    "\n",
    "#         # Initializing hidden state for first input using method defined below\n",
    "#         hidden = self.init_hidden(batch_size)\n",
    "\n",
    "#         # Passing in the input and hidden state into the model and obtaining outputs\n",
    "#         out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "#         # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "#         out = out.contiguous().view(-1, self.hidden_dim)\n",
    "#         out = self.linear(out)\n",
    "        \n",
    "#         return out, hidden\n",
    "    \n",
    "#     def init_hidden(self, batch_size):\n",
    "#         # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "#         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "#         hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "#         return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
